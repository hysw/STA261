\section{Topics for First Midterm}


\subsection{Basic Definitions}

\begin{description}
\item[norm]\hfill\\
	see note \hyperref[def:norm]{basic:definations:norm}
\item[inner product]\hfill\\
	see note \hyperref[def:innerprod]{basic:definations:inner product}
\item[metric / distance functions]\hfill\\
	see note \hyperref[def:metric]{basic:definations:metric}
\item[open and closed subset of metric space]\hfill\\
	see note \hyperref[def:metric]{basic:definations:metricspace-openset}
		and \hyperref[def:metric]{basic:definations:metricspace-closedset}
\end{description}

\subsection{Basic Theorems}
\begin{description}
\item[EVT] \hyperref[thm:evt]{Extreme value theorem}
\item[IVT] \hyperref[thm:ivt]{Intermediate value theorem}
\item[MVT] \hyperref[thm:mvt]{Mean value theorem}
\item[IVFT] \nameref{thm_ivft}
\item[IPFT] \nameref{thm_ipft}
\end{description}

\subsection{Basic topology of metric spaces}

\begin{description}

\item[closure]\hfill\\
	the set with all its limit points

\item[interior]\hfill\\
	union of all open set contained in A

\item[exterior]\hfill\\
	union of all open set disjoint from A

\item[boundary]\hfill\\
	points that are neither interior nor exterior

\item[limits] $f:A\subseteq X\to Y$\hfill\\
$f(x)\to y_0 \textrm{ as } x\to x_0$ if
$\forall \ \mathrm{open} \ V\ni y_0 \ \exists \ \mathrm{open} \ U\ni x_0
	\ [x\in U\cap A \wedge x\neq x_0 \to f(x)\in V]$

\item[continuity]
	f is cts at $x_0$ if $x_0$ is isolated point or $(\lim_{x\to x_0}f(x)) = f(x_0)$

\item[Cauchy sequences] A sequences $\langle x_i\rangle$ is Cauchy if\hfill\\
	$\forall \varepsilon \exists N [n,m>N\implies d(x_m, x_n)<\varepsilon]$

\item[completeness]
	A metric space $X$ is complete if every Cauchy sequences converge(to some point in $X$).

\item[compact sets]
	every open cover of $X$ has a finite subcover

\item[connected sets]
	$X$ cannot be divided into two disjoint nonempty closed/open/clopen sets.

\item[relatively open sets] p26
	$A$ is relatively open in $Y\subseteq X$ if $\exists$ open $U\subseteq X$ such that $A=U\cap Y$

\item[Proposition]
	$f : X \to Y$ is cts iff $\forall$ open $ V \in Y$, $F^{-1}(V)$ is open in $X$.
	Similarly for closed.

\item[Bolzano–Weierstrass property] \hfill\\
	A subset $E \in \mathbb{R}^n$ satisfies the BW property if every suquence has a convergent subsequence.

\item[Bolzano–Weierstrass theorem]
	$E \in \mathbb{R}^n$ satisfies the BW property iff $E$ is closed and bounded.

\item[Heine-Borel theorem] $E \in \mathbb{R}^n$ is compact iff $E$ is closed and bounded.
\item[Application/(topological invariant)] Suppose $f:X \to Y$ is continuous and X is compact then $f(X)$ is compact
\item[Extreme value theorem] Suppose $f:X \to \mathbb{R}$ is continuous and X is compact then $\exists x_0 \in X$
such that $f(x) \leq f(x_0) \forall x \in X$.
\item[Path connected] A set $E$ is path connected if $\forall x, y \in E$, $\exists$ continuous
map $f:[a, b] \to E$ such that $f(a) = x$ and $f(b) = y$.
\item[Proposition] If $E$ is connected, and $f:E \to Y$ is continuous then $f(E)$ is connected
\item[Proposition] If $E$ is path connected then $E$ is connected.
\item[Intermediate Value Theorem] Suppose $E \in \mathbb{R}$ is connected and $f: E \to \mathbb{R}$
is continuous. Suppose $f(x) = a$ and $f(y) = b$ for some $x, y \in E$ and $a < b$.
Then $\forall a < c < b \exists$ some $z \in E$ such that $f(z) = c$.
\item[The $\epsilon$-neighborhood theorem] Let $X$ be a compact subspace of $\mathbb{R}$; Let $U$ be an open set of $\mathbb{R}^n$
contaioning $X$, Then there is an $\epsilon > 0$ such that the $\epsilon$-neighborhood of $X$ is contained in $U$.
\end{description}

Cauchy-Schwarz inequality; all norms on a finite-dimensional vector
space are equivalent; Bolzano Weierstrass theorem; Heine-Borel theorem; the con-
tinuous image of a compact set is compact; the continuous image of a connected
set is connected; intermediate value theorem; extreme value theorem. minima and
maxima of continuous functions on compact sets
\subsection{Differentiation}


\begin{description}
\item[Derivative]\hfill
	\begin{itemize}
		\item \hyperref[def:differentiable]{definition of the differentiable}
		\item \hyperref[def:partial_derivative]{partial derivatives}
		\item \hyperref[def:directional_derivative]{directional derivatives}
	\end{itemize}
\item[chain rule]\hfill
	\begin{itemize}
	\item$(f\circ g) = (f' \circ g)\cdot g'$
	\item$\frac{d f}{d x} = \frac{d f}{d g}\cdot \frac{d g}{d x}$
	\end{itemize}
\item[continuity and differentiability]\hfill
	\begin{itemize}
	\item differentiable implies continuity
	\item $C^1$ implies differentiable
	\item $C^2$ implies equality of mixed partial derivatives
	\end{itemize}
\item[Jacobian matrix]\hfill\\
	$
	Jf = \begin{bmatrix}
	  \frac{\partial f_1}{\partial x_1} & \cdots & \frac{\partial f_1}{\partial x_n}\\
	  \ldots & \ddots & \ldots \\
	  \frac{\partial f_m}{\partial x_1} & \cdots & \frac{\partial f_m}{\partial x_n}
	 \end{bmatrix}
	$
\item[continuously differentiable functions]
	if the derivative exists and the derivative is continuous
\item[higher order derivatives]
	second derivative or higher
\item[gradient]
	$\vec\nabla f = \sum_i (D_if)e_i$
	(aka, $(\nabla f(x)) \cdot v = f'(x;v)$)
\item[geometry of the Jacobian, the rows, the columns]TODO
\end{description}


\subsection{Max-min problems}

\begin{description}
\item[\nameref{multiindex}] see note
\item[\nameref{thm:taylor}] The taylor series is useful at critical points because if $a$ is a critical point of $f$ and $f$ is $C^2$ at $a$ then
\begin{align*}
f(a+h) = f(a) + \frac{1}{2}\sum\limits_{i, j = 1}^{n} \partial_i \partial_j f(a)h^i h^j + R_{a,2}(h)
\end{align*}
where
\begin{align*}
R_{a,2}(h) \rightarrow 0 \text{ as } x \rightarrow 0
\end{align*}
\item[Basic facts about the gradient] $\nabla f(a)$ points in the direction of maximal increase and $|\nabla f(a)|$ is the rate of change of $f$ in the direction of fastest increase. $\nabla f(a)$ is orthogonal to the level set of $f$ that passes through $a$.
\item[Critical points] $a \in \mathbb{R}$ is said to be a critical point of $f$ if $Df = 0$.
\item[Proposition] If $f$ has a local maximum/minimum at $a$ and $f$ is differentiable at $a$ then $Df(a) = 0$.
\item[the Hessian] $H(f) = (D_i D_j f(a))$ which has $n$ eigenvalues counting multiplicity.
\item[Hessian Matrix]\hfill\\
$H(f) = \begin{bmatrix}
\frac{\partial^2 f}{\partial x_1\partial x_1} & \cdots & \frac{\partial^2 f}{\partial x_1\partial x_n}\\
\ldots & \ddots & \ldots \\
\frac{\partial^2 f}{\partial x_n\partial x_1} & \cdots & \frac{\partial^2 f}{\partial x_n\partial x_n}
\end{bmatrix}$
\item[Minors] A $k \times k$ principle minor of a matrix $M$ is the matrix restricted to the first $k$ rows and the first $k$ columns.
\item[Quadratic forms] Completing the square.
\item[Proposition] A symmetric matrix $h$ is positive definate if the determinant of all its principle $k \times k$ minors are positive.
\item[Classification of critical points]
Suppose $f: \mathbb{R}^n \to \mathbb{R}^n$ is $c^2$, $a$ is a critical point. Then $H(f)$ has $n$ eigenvalues (counting multiplicity).
	\begin{itemize}
		\item $a$ is a local minimum of all eigenvalues are positive.
		\item $a$ is a local maximum if all eigenvalues are negative.
		\item $a$ is a saddle point if $k$ eigenvalues are positive and $n-k$ are negative.
		\item $a$ is a non-degenerate critical point if all eigenvalues are non-zero
	\end{itemize}
\item[Folland 2.82] Suppose $f$ is of class $C^2$ on an open set in $\mathbb{R}^2$ containing the point a, and suppose $Df(a) = 0$. Let $\alpha = \partial_1^2 f(a)$, $\beta = \partial_1\partial_2 f(a)$, $\gamma = \partial_2^2 f(a)$. Then:
	\begin{itemize}
		\item If $\alpha\gamma - \beta^2 < 0$, $f$ has a saddle point at $a$.
		\item If $\alpha\gamma - \beta^2 > 0$ and $\alpha > 0$, $f$ has a local minimum at $a$.
		\item If $\alpha\gamma - \beta^2 > 0$ and $\alpha < 0$, $f$ has a local maximum at $a$.
		\item If $\alpha\gamma - \beta^2 = 0$, no conclusion can be drawn.
	\end{itemize}
\item[Max-min problems with constraints]
Apply the classification of critical points for points in the interior. On the boundary use lagrange multipliers.
\item[Lagrange multipliers]
Consider the functions $f: \mathbb{R}^n \to \mathbb{R}$ and $g_1: \mathbb{R}^n \to \mathbb{R}$ and $g_2: \mathbb{R}^n \to \mathbb{R}$. We want to find the extreme values for $f$ subject to $g_1 = c_1$ and $g_2 = c_2$. Then we just need find the values $a \in \mathbb{R}^n$ that satisfy the system of equations:
	\begin{itemize}
		\item $\nabla f(a) = \mu \nabla g_1(a) + \lambda \nabla g_2(a)$
		\item $g_1(a) = c_1$
		\item $g_2(a) = c_2$
	\end{itemize}
\end{description}



\subsection{Instructor's comment}
General Comments: Should you memorize proofs of theorems? It is very hard to
memorize all proofs of all theorems. In the long run, it is much more efficient, as well
as useful and interesting, to first try to understand the proofs, and internalize the
methods of proof, as well as possible; then to remember just an outline of the proof,
or some key idea; roughly speaking, the minimum you would need to allow yourself
to reconstruct the proof out of your base of general knowledge/understanding.
Remember: it is important to know not simply whether something is true, but why
it is true.



