\subsection{Monday, July 6, 2015}

A \kw{statistic} $t(X)$ is a function of data $X$ or sample and \hl{not} the parameter.

\subsubsection{Statistical Model}
A \kw{statistical model} is a set of assertions that directly or indirectly specify the proboblity distribution of observed data.

% TODO

\subsubsection{Estimator}



\subsubsection{Statistical Inference}
estimation($\hat \theta$, a estimator of $\theta$)

hypothesis testing estimation($\hat \theta$)


estimator is a statistic $\hat \theta(X_1,\ldots,X_n)$
estimator $\hat \theta$ is a statistic of data sample $(X_1,\ldots,X_n)$

\begin{itemize}
\item Proboblity model
\item statistic model
\item statistic Inference
\item principal of minimizaing MSE
\item Method of moment estimator
\item parameter space
\item biased estimator / unbiased estimator
\item consistant estimator
\item MVUE - Minimum-variance unbiased estimator
\end{itemize}


% DISCARD

An \textit{estimator} is a rule, often expressed as a formula, that tells how to calculate the value of an estimate based on the measurements contained in a sample.

Let $\hat{\theta}$ be a point estimator for a parameter $\theta$. Then $\hat{\theta}$ is an \textit{unbiased estimator} if $\E(\hat{\theta}) = \theta$. If $E(\hat{\theta}) \neq \hat{\theta}$, $\hat{\theta}$ is said to be \textit{biased}.

The \textit{bias} of a point estimator $\hat{\theta}$ is given by $B(\hat{\theta}) = E(\hat{\theta})-\theta$.

The \textit{mean square error} of a point estimator $\hat{\theta}$ is
\[\MSE(\hat{\theta})=\E[(\hat{\theta}-\theta)^2]=\Var(\hat{\theta})+ [\B(\hat{\theta})]^2\]

Define \textit{standard error} $\sigma_{\hat\theta}=\sqrt{\sigma^2_{\hat\theta}}$.


The error of estimation $\eps$ is the distance between an estimator and its target parameter. That is, $\eps = |\hat{\theta}-\theta|$.


Statistical Model and Inference
Method of Moment Estimator